{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c_Oj4IfhbSfw"
      },
      "source": [
        "**Task 1:- Data Preprocessing**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 777
        },
        "id": "e7fj8FHeCMUb",
        "outputId": "352a1d83-2d82-4a31-f68b-a09b4db0e014"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Load dataset\n",
        "telco = pd.read_csv('/content/Telco_Customer_Churn_Dataset.csv')\n",
        "\n",
        "#missing Value\n",
        "print(\"\\nMissing value in each column: \")\n",
        "telco.isnull().sum()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DHwXv3PSFAqc",
        "outputId": "e35620f2-a74a-4c97-e28e-05f570935abe"
      },
      "outputs": [],
      "source": [
        "#One Hot Encoding\n",
        "telco['TotalCharges'] = pd.to_numeric(telco['TotalCharges'], errors='coerce')\n",
        "telco['TotalCharges'] = telco['TotalCharges'].fillna(telco['TotalCharges'].median())\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "le = LabelEncoder()\n",
        "telco['Churn'] = le.fit_transform(telco['Churn'])\n",
        "\n",
        "telco = telco.drop(columns=['customerID'])\n",
        "\n",
        "# One-Hot Encode to all categorical variables\n",
        "telco = pd.get_dummies(telco, drop_first=True)\n",
        "\n",
        "\n",
        "print(telco.info())\n",
        "\n",
        "telco = telco.astype('float64')\n",
        "\n",
        "print(telco.dtypes)\n",
        "\n",
        "print(telco.head())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "86PZoZGWE0zT"
      },
      "source": [
        "**Task 2 :-Split Data for Training and Testing**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dCVH-jTxCvKT",
        "outputId": "58c43f1d-e3b7-4457-8834-b62dd82acf48"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X = telco.drop('Churn', axis=1)  # Features\n",
        "y = telco['Churn']  # Target variable\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.2, random_state = 1)\n",
        "print(X_train)\n",
        "print(X_test)\n",
        "print(y_train)\n",
        "print(y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RpclzWtpH-In"
      },
      "source": [
        "**Task 3 - Feature Selection**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 900
        },
        "id": "R7rgQ0FpHHlU",
        "outputId": "e211e593-9100-42d6-9db2-17d7abad43f8"
      },
      "outputs": [],
      "source": [
        "#Correlation_Matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "correlation_matrix = telco.corr()\n",
        "plt.figure(figsize=(15,10))\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', annot_kws={'size':8}, fmt = '.2f', linewidths=.5)\n",
        "plt.title('Correlation Matrix')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bgyo_e3LPLXE"
      },
      "source": [
        "In here we have got Contract_Two year\t(-0.30) Customers on 2-year contracts are less likely to churn.\n",
        "\n",
        "Contract_One year\t(-0.20) Similar effect but less strong.\n",
        "\n",
        "tenure\t(-0.35) Higher tenure = more loyal = lower churn.\n",
        "\n",
        "OnlineSecurity_Yes\t(-0.28) Customers with online security are less likely to leave.\n",
        "\n",
        "TechSupport_Yes\t(-0.27) Support availability reduces churn.\n",
        "\n",
        "MonthlyCharges\t(+0.19) Slightly higher charges â†’ more churn (but weak).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "AN83OouhP6ua"
      },
      "outputs": [],
      "source": [
        "Selected_features = ['Contract_Two year', 'Contract_One year', 'tenure', 'OnlineSecurity_Yes', 'TechSupport_Yes', 'MonthlyCharges']\n",
        "X = telco[Selected_features]\n",
        "y = telco['Churn']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Xz9EAHuZRR0A"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.2, random_state = 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "pqRdS2r4Rduk"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.transform(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jjU7ALGa3VkJ"
      },
      "source": [
        "***Task 4 - Model Selection***\n",
        "\n",
        "\n",
        "- **Logistic Regression**: Chosen for interpretability and suitability for binary classification with scaled features.\n",
        "- **Decision Tree**: Selected to capture non-linear relationships in features like `tenure` and `Contract`.\n",
        "- **Random Forest**: Used for robustness and handling categorical features post one-hot encoding.\n",
        "- **Gradient Boosting**: Included for improved performance on imbalanced data.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i9yLlNF1SvLC"
      },
      "source": [
        "**Task 5 :- Model Training**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "id": "MmfDQb-xS3nb",
        "outputId": "a18bef66-520d-4a9d-e140-9272e4495bf2"
      },
      "outputs": [],
      "source": [
        "#Logistic Regression\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "Classifier = LogisticRegression(random_state = 0)\n",
        "Classifier.fit(X_train, y_train)\n",
        "\n",
        "LogisticRegression(random_state=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "JktOV7UmUfdX"
      },
      "outputs": [],
      "source": [
        "y_pred = Classifier.predict(X_test)\n",
        "y_pred_proba = Classifier.predict_proba(X_test)  # Predicted probabilities\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "id": "g47JMsjyZ8D2",
        "outputId": "540e6b08-efa4-4bd5-b5f1-ebdc10858f6b"
      },
      "outputs": [],
      "source": [
        "#Decision Tress\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "Classifier = DecisionTreeClassifier(criterion = 'entropy', random_state = 0)\n",
        "Classifier.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "id": "tun7QDweaYcP",
        "outputId": "1e032900-2f6b-4ebe-af78-7669fbfe545a"
      },
      "outputs": [],
      "source": [
        "#Random Forest\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "Classifier = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 0)\n",
        "Classifier.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "id": "iTo_cEwWaoxZ",
        "outputId": "db7cee7d-2be0-40ad-b2f2-0f31a507899b"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "\n",
        "# Train GB model\n",
        "gb_model = GradientBoostingClassifier(random_state=0)\n",
        "gb_model.fit(X_train, y_train)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E46KFyWQaxMp"
      },
      "source": [
        "**TASK 6 :- MODEL EVALUATION**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hk22w1BTU7Zo",
        "outputId": "ca66c71d-6e85-49ea-a5b1-0f7e2b60f0da"
      },
      "outputs": [],
      "source": [
        "#Logistic Regression\n",
        "\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score\n",
        "auc_score = roc_auc_score(y_test, y_pred_proba[:, 1])\n",
        "\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "\n",
        "\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
        "\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
        "\n",
        "print(\"AUC Score:\\n\", auc_score)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aPGZMCjZZNq7",
        "outputId": "1c74b6ea-bde6-420b-d804-23f2d9ba35b6"
      },
      "outputs": [],
      "source": [
        "#Decision Tree\n",
        "\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "dt_classifier = DecisionTreeClassifier(criterion = 'entropy', random_state = 0)\n",
        "dt_classifier.fit(X_train, y_train)\n",
        "\n",
        "dt_y_pred = dt_classifier.predict(X_test)\n",
        "dt_y_pred_proba = dt_classifier.predict_proba(X_test)\n",
        "auc_score_dt = roc_auc_score(y_test, dt_y_pred_proba[:, 1])\n",
        "print(\"Decision Tree - Accuracy:\", accuracy_score(y_test, dt_y_pred))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, dt_y_pred))\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, dt_y_pred))\n",
        "print(\"Decision Tree AUC Score:\", auc_score_dt)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tof-68TTcHhg",
        "outputId": "541cd6a6-37da-48cb-c094-3bba06c72123"
      },
      "outputs": [],
      "source": [
        "#Random Forest\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "rf_classifier = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 0) # Initialize rf_classifier\n",
        "rf_classifier.fit(X_train, y_train)\n",
        "\n",
        "rf_y_pred = rf_classifier.predict(X_test)\n",
        "rf_y_pred_proba = rf_classifier.predict_proba(X_test)\n",
        "auc_score_rf = roc_auc_score(y_test, rf_y_pred_proba[:, 1])\n",
        "print(\"Random Forest - Accuracy:\", accuracy_score(y_test, rf_y_pred))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, rf_y_pred))\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, rf_y_pred))\n",
        "print(\"Random Forest AUC Score:\", auc_score_rf)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4w7K3YhTbxnV",
        "outputId": "78bb6456-9843-435a-8a0d-6b304b8c863d"
      },
      "outputs": [],
      "source": [
        "#Gradiant Boost\n",
        "\n",
        "y_pred_gb = gb_model.predict(X_test)\n",
        "y_pred_gb_proba = gb_model.predict_proba(X_test)  # Predicted probabilities\n",
        "\n",
        "\n",
        "\n",
        "print(\"Gradient Boosting Classifier:\")\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred_gb))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_gb))\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_gb))\n",
        "auc_score_gb = roc_auc_score(y_test, y_pred_gb_proba[:, 1])\n",
        "print(\"Gradient Boosting AUC Score:\", auc_score_gb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "waiTLy1-eoSj"
      },
      "source": [
        "The Summary Table for all evaluation of algorithms used in this .\n",
        "\n",
        "\n",
        "### Model Evaluation Summary\n",
        "| Model               | Accuracy | Class 1 Recall | Class 1 Precision | F1 (Class 1) | ROC-AUC |\n",
        "|---------------------|----------|----------------|-------------------|--------------|---------|\n",
        "| Logistic Regression | 0.791    | 0.49           | 0.63              | 0.55         | 0.818   |\n",
        "| Decision Tree       | 0.717    | 0.41           | 0.45              | 0.43         | 0.631   |\n",
        "| Random Forest       | 0.752    | 0.44           | 0.53              | 0.48         | 0.761   |\n",
        "| Gradient Boosting   | 0.785    | 0.48           | 0.61              | 0.54         | 0.825   |\n",
        "\n",
        "\n",
        "### Model Evaluation Insights\n",
        "Logistic Regression (0.791 accuracy, 0.818 ROC-AUC) and Gradient Boosting (0.785 accuracy, 0.825 ROC-AUC) lead, but low Class 1 recall (0.49, 0.48) shows difficulty predicting churners due to class imbalance (~26% churn). Decision Tree (0.717 accuracy, 0.631 ROC-AUC) overfits. Random Forest (0.752 accuracy, 0.761 ROC-AUC) is moderate. SMOTE could improve recall.\n",
        "Thank You"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
